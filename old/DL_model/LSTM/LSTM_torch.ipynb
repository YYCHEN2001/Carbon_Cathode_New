{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T09:22:13.339970Z",
     "start_time": "2024-12-03T09:22:11.870821Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:22:14.681496Z",
     "start_time": "2024-12-03T09:22:14.183668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"../../data/dataset.csv\")\n",
    "data['target_class'] = pd.qcut(data['Cs'], q=10, labels=False)\n",
    "X = data.drop(['Cs', 'target_class'], axis=1)\n",
    "y = data['Cs']\n",
    "stratify_column = data['target_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=stratify_column)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 将数据转换为张量\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 20\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "fd5981b170952c33",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:22:17.108200Z",
     "start_time": "2024-12-03T09:22:16.291491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_function import MAPE_Loss, RMSE_Loss\n",
    "# 定义 LSTM 模型\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.3):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.num_layers = len(hidden_sizes)\n",
    "\n",
    "        # Defining multiple LSTM layers with configurable hidden sizes\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        for i in range(self.num_layers):\n",
    "            input_dim = input_size if i == 0 else hidden_sizes[i-1]\n",
    "            lstm_dropout = dropout if self.num_layers > 1 and i < self.num_layers - 1 else 0\n",
    "            self.lstm_layers.append(nn.LSTM(input_dim, hidden_sizes[i], batch_first=True, dropout=lstm_dropout))\n",
    "\n",
    "        # Fully connected layer for output\n",
    "        self.fc = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x, seq_lengths=None):\n",
    "        # Initial hidden and cell state for each layer\n",
    "        h0 = [torch.zeros(1, x.size(0), hidden_size).to(x.device) for hidden_size in self.hidden_sizes]\n",
    "        c0 = [torch.zeros(1, x.size(0), hidden_size).to(x.device) for hidden_size in self.hidden_sizes]\n",
    "\n",
    "        # Forward propagate through each LSTM layer\n",
    "        out = x\n",
    "        for i, lstm in enumerate(self.lstm_layers):\n",
    "            if seq_lengths is not None:\n",
    "                packed_input = nn.utils.rnn.pack_padded_sequence(out, seq_lengths, batch_first=True, enforce_sorted=False)\n",
    "                packed_output, (h, c) = lstm(packed_input, (h0[i], c0[i]))\n",
    "                out, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "            else:\n",
    "                out, (h, c) = lstm(out, (h0[i], c0[i]))\n",
    "\n",
    "        # Decode the hidden state of the last time step using average pooling\n",
    "        out = torch.mean(out, dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Set model parameters\n",
    "input_size = X_train_scaled.shape[1]  # Number of features per time step\n",
    "hidden_sizes = [64, 64]  # LSTM hidden sizes\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMRegressor(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "# criterion = nn.MSELoss().to(device)\n",
    "# criterion = MAPE_Loss().to(device)\n",
    "criterion = RMSE_Loss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Reshape input for LSTM (batch_size, sequence_length, input_size)\n",
    "def reshape_for_lstm(X):\n",
    "    return X.unsqueeze(1)  # Add a sequence length dimension of 1"
   ],
   "id": "3df9490589a74d9e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:22:41.615562Z",
     "start_time": "2024-12-03T09:22:20.961482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training the model\n",
    "num_epochs = 3000\n",
    "best_loss = float('inf')\n",
    "cumulative_loss = 0.0\n",
    "patience = 30  # 允许的最大连续未改进 epoch 数\n",
    "epochs_without_improvement = 0  # 连续未改进的 epoch 数\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = reshape_for_lstm(X_batch)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        cumulative_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        average_loss = cumulative_loss / 10\n",
    "        print(f'Epoch {epoch+1}, Average Loss: {average_loss:.4f}')\n",
    "        cumulative_loss = 0.0  # Reset cumulative loss\n",
    "\n",
    "    # 计算验证损失\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            X_batch = reshape_for_lstm(X_batch)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.squeeze(), y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        val_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # 判断验证损失是否改善\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_without_improvement = 0  # 重置计数器\n",
    "        # 保存最佳模型\n",
    "        torch.save(model.state_dict(), \"lstm_best_model.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # 如果验证损失在一定次数的 epoch 内没有改进，则停止训练\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break"
   ],
   "id": "1c145a4951631b53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 2072.9601\n",
      "Epoch 20, Average Loss: 1472.7975\n",
      "Epoch 30, Average Loss: 1118.3476\n",
      "Epoch 40, Average Loss: 911.6968\n",
      "Epoch 50, Average Loss: 777.2453\n",
      "Epoch 60, Average Loss: 681.1015\n",
      "Epoch 70, Average Loss: 589.1796\n",
      "Epoch 80, Average Loss: 499.4675\n",
      "Epoch 90, Average Loss: 430.2941\n",
      "Epoch 100, Average Loss: 375.4505\n",
      "Epoch 110, Average Loss: 337.4149\n",
      "Epoch 120, Average Loss: 309.2961\n",
      "Epoch 130, Average Loss: 286.1842\n",
      "Epoch 140, Average Loss: 270.2180\n",
      "Epoch 150, Average Loss: 258.9182\n",
      "Epoch 160, Average Loss: 251.4347\n",
      "Epoch 170, Average Loss: 242.0240\n",
      "Epoch 180, Average Loss: 234.8365\n",
      "Epoch 190, Average Loss: 224.9844\n",
      "Epoch 200, Average Loss: 220.4263\n",
      "Epoch 210, Average Loss: 210.3852\n",
      "Epoch 220, Average Loss: 206.6671\n",
      "Epoch 230, Average Loss: 205.0047\n",
      "Epoch 240, Average Loss: 203.2370\n",
      "Epoch 250, Average Loss: 193.1271\n",
      "Epoch 260, Average Loss: 188.1166\n",
      "Epoch 270, Average Loss: 186.0072\n",
      "Epoch 280, Average Loss: 177.5227\n",
      "Epoch 290, Average Loss: 174.1834\n",
      "Epoch 300, Average Loss: 172.7302\n",
      "Epoch 310, Average Loss: 172.0630\n",
      "Epoch 320, Average Loss: 169.6896\n",
      "Epoch 330, Average Loss: 159.6520\n",
      "Epoch 340, Average Loss: 160.2922\n",
      "Epoch 350, Average Loss: 167.2641\n",
      "Epoch 360, Average Loss: 157.6775\n",
      "Epoch 370, Average Loss: 158.9793\n",
      "Epoch 380, Average Loss: 157.2822\n",
      "Epoch 390, Average Loss: 153.4481\n",
      "Epoch 400, Average Loss: 150.2601\n",
      "Epoch 410, Average Loss: 150.6447\n",
      "Epoch 420, Average Loss: 147.6083\n",
      "Epoch 430, Average Loss: 149.5245\n",
      "Early stopping at epoch 431\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T09:22:45.545370Z",
     "start_time": "2024-12-03T09:22:45.105795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from function import calculate_metrics, metrics_to_dataframe\n",
    "\n",
    "# 加载最佳模型的状态字典\n",
    "model.load_state_dict(torch.load(\"lstm_best_model.pth\", weights_only=True))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 准备训练数据\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_predictions = []\n",
    "    y_train_true = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = reshape_for_lstm(X_batch)\n",
    "        outputs = model(X_batch)\n",
    "        train_predictions.append(outputs.cpu().numpy())\n",
    "        y_train_true.append(y_batch.cpu().numpy())\n",
    "\n",
    "    train_predictions = np.concatenate(train_predictions, axis=0)\n",
    "    y_train_true = np.concatenate(y_train_true, axis=0)\n",
    "\n",
    "    # 计算训练集的指标\n",
    "    train_metrics = calculate_metrics(y_train_true, train_predictions)\n",
    "    print(\"训练集指标:\", train_metrics)\n",
    "\n",
    "    # 准备测试数据\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_predictions = []\n",
    "    y_test_true = []\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = reshape_for_lstm(X_batch)\n",
    "        outputs = model(X_batch)\n",
    "        test_predictions.append(outputs.cpu().numpy())\n",
    "        y_test_true.append(y_batch.cpu().numpy())\n",
    "\n",
    "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "    y_test_true = np.concatenate(y_test_true, axis=0)\n",
    "\n",
    "    # 计算测试集的指标\n",
    "    test_metrics = calculate_metrics(y_test_true, test_predictions)\n",
    "    print(\"测试集指标:\", test_metrics)\n",
    "\n",
    "    # 将结果转换为DataFrame\n",
    "    lstm_metrics = metrics_to_dataframe(\n",
    "        y_train_true, train_predictions,\n",
    "        y_test_true, test_predictions, \"LSTM\").round(3)\n",
    "    lstm_metrics.to_csv('LSTM_metrics.csv', index=False)\n",
    "    print(lstm_metrics)\n"
   ],
   "id": "b8b38ebb7b444f9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集指标: (0.975204586982727, 3.1265738, 2.972951903939247, 6.2861323)\n",
      "测试集指标: (0.9539355039596558, 5.4024215, 6.594595313072205, 8.51768)\n",
      "  model  R2_train  MAE_train  MAPE_train  RMSE_train  R2_test  MAE_test  \\\n",
      "0  LSTM     0.975      3.127       2.973       6.286    0.954     5.402   \n",
      "\n",
      "   MAPE_test  RMSE_test  \n",
      "0      6.595      8.518  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:33:09.100110Z",
     "start_time": "2024-11-26T10:33:09.053373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存预测结果\n",
    "lstm_train = pd.DataFrame({'Actual': y_train_true, 'Predicted': train_predictions.squeeze()})\n",
    "lstm_test = pd.DataFrame({'Actual': y_test_true, 'Predicted': test_predictions.squeeze()})\n",
    "lstm_train.to_csv('lstm_train.csv', index=False)\n",
    "lstm_test.to_csv('lstm_test.csv', index=False)"
   ],
   "id": "89a0b250ede65b92",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

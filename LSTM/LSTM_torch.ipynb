{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T07:03:58.788324Z",
     "start_time": "2024-11-26T07:03:54.906456Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T07:04:00.751372Z",
     "start_time": "2024-11-26T07:03:58.791331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"../data/dataset.csv\")\n",
    "data['target_class'] = pd.qcut(data['Cs'], q=10, labels=False)\n",
    "X = data.drop(['Cs', 'target_class'], axis=1)\n",
    "y = data['Cs']\n",
    "stratify_column = data['target_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=stratify_column)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 将数据转换为张量\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 20\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "fd5981b170952c33",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T07:04:01.865451Z",
     "start_time": "2024-11-26T07:04:01.036163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_loss import MAPE_Loss, RMSE_Loss\n",
    "# 定义 LSTM 模型\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.3):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.num_layers = len(hidden_sizes)\n",
    "\n",
    "        # Defining multiple LSTM layers with configurable hidden sizes\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        for i in range(self.num_layers):\n",
    "            input_dim = input_size if i == 0 else hidden_sizes[i-1]\n",
    "            lstm_dropout = dropout if self.num_layers > 1 and i < self.num_layers - 1 else 0\n",
    "            self.lstm_layers.append(nn.LSTM(input_dim, hidden_sizes[i], batch_first=True, dropout=lstm_dropout))\n",
    "\n",
    "        # Fully connected layer for output\n",
    "        self.fc = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x, seq_lengths=None):\n",
    "        # Initial hidden and cell state for each layer\n",
    "        h0 = [torch.zeros(1, x.size(0), hidden_size).to(x.device) for hidden_size in self.hidden_sizes]\n",
    "        c0 = [torch.zeros(1, x.size(0), hidden_size).to(x.device) for hidden_size in self.hidden_sizes]\n",
    "\n",
    "        # Forward propagate through each LSTM layer\n",
    "        out = x\n",
    "        for i, lstm in enumerate(self.lstm_layers):\n",
    "            if seq_lengths is not None:\n",
    "                packed_input = nn.utils.rnn.pack_padded_sequence(out, seq_lengths, batch_first=True, enforce_sorted=False)\n",
    "                packed_output, (h, c) = lstm(packed_input, (h0[i], c0[i]))\n",
    "                out, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "            else:\n",
    "                out, (h, c) = lstm(out, (h0[i], c0[i]))\n",
    "\n",
    "        # Decode the hidden state of the last time step using average pooling\n",
    "        out = torch.mean(out, dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Set model parameters\n",
    "input_size = X_train_scaled.shape[1]  # Number of features per time step\n",
    "hidden_sizes = [64, 64]  # LSTM hidden sizes\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMRegressor(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "# criterion = nn.MSELoss().to(device)\n",
    "# criterion = MAPE_Loss().to(device)\n",
    "criterion = RMSE_Loss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Reshape input for LSTM (batch_size, sequence_length, input_size)\n",
    "def reshape_for_lstm(X):\n",
    "    return X.unsqueeze(1)  # Add a sequence length dimension of 1"
   ],
   "id": "3df9490589a74d9e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T07:04:16.843824Z",
     "start_time": "2024-11-26T07:04:01.891529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training the model\n",
    "num_epochs = 3000\n",
    "best_loss = float('inf')\n",
    "cumulative_loss = 0.0\n",
    "patience = 30  # 允许的最大连续未改进 epoch 数\n",
    "epochs_without_improvement = 0  # 连续未改进的 epoch 数\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = reshape_for_lstm(X_batch)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        cumulative_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        average_loss = cumulative_loss / 10\n",
    "        print(f'Epoch {epoch+1}, Average Loss: {average_loss:.4f}')\n",
    "        cumulative_loss = 0.0  # Reset cumulative loss\n",
    "\n",
    "    # 计算验证损失\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            X_batch = reshape_for_lstm(X_batch)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.squeeze(), y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        val_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # 判断验证损失是否改善\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_without_improvement = 0  # 重置计数器\n",
    "        # 保存最佳模型\n",
    "        torch.save(model.state_dict(), \"lstm_best_model.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # 如果验证损失在一定次数的 epoch 内没有改进，则停止训练\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break"
   ],
   "id": "1c145a4951631b53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 1138.0962\n",
      "Epoch 20, Average Loss: 933.9295\n",
      "Epoch 30, Average Loss: 796.3857\n",
      "Epoch 40, Average Loss: 685.7720\n",
      "Epoch 50, Average Loss: 598.3578\n",
      "Epoch 60, Average Loss: 531.2694\n",
      "Epoch 70, Average Loss: 478.2677\n",
      "Epoch 80, Average Loss: 436.4876\n",
      "Epoch 90, Average Loss: 401.9465\n",
      "Epoch 100, Average Loss: 370.6355\n",
      "Epoch 110, Average Loss: 344.3074\n",
      "Epoch 120, Average Loss: 321.7657\n",
      "Epoch 130, Average Loss: 286.9535\n",
      "Epoch 140, Average Loss: 258.7404\n",
      "Epoch 150, Average Loss: 238.4087\n",
      "Epoch 160, Average Loss: 218.3724\n",
      "Epoch 170, Average Loss: 202.1486\n",
      "Epoch 180, Average Loss: 185.8503\n",
      "Epoch 190, Average Loss: 176.5312\n",
      "Epoch 200, Average Loss: 170.9059\n",
      "Epoch 210, Average Loss: 164.0966\n",
      "Epoch 220, Average Loss: 161.3290\n",
      "Epoch 230, Average Loss: 157.2208\n",
      "Epoch 240, Average Loss: 150.9569\n",
      "Epoch 250, Average Loss: 142.2093\n",
      "Epoch 260, Average Loss: 135.6740\n",
      "Epoch 270, Average Loss: 131.8765\n",
      "Epoch 280, Average Loss: 128.5486\n",
      "Epoch 290, Average Loss: 124.8343\n",
      "Epoch 300, Average Loss: 119.8140\n",
      "Epoch 310, Average Loss: 118.2179\n",
      "Epoch 320, Average Loss: 113.3663\n",
      "Epoch 330, Average Loss: 113.1705\n",
      "Epoch 340, Average Loss: 110.5410\n",
      "Epoch 350, Average Loss: 107.2348\n",
      "Epoch 360, Average Loss: 107.1224\n",
      "Epoch 370, Average Loss: 103.7714\n",
      "Epoch 380, Average Loss: 101.6528\n",
      "Epoch 390, Average Loss: 100.0549\n",
      "Epoch 400, Average Loss: 99.1966\n",
      "Epoch 410, Average Loss: 99.0598\n",
      "Epoch 420, Average Loss: 93.5251\n",
      "Epoch 430, Average Loss: 93.8172\n",
      "Epoch 440, Average Loss: 92.4864\n",
      "Epoch 450, Average Loss: 91.4886\n",
      "Epoch 460, Average Loss: 93.4234\n",
      "Epoch 470, Average Loss: 91.0069\n",
      "Epoch 480, Average Loss: 88.2180\n",
      "Epoch 490, Average Loss: 89.1121\n",
      "Epoch 500, Average Loss: 86.9821\n",
      "Epoch 510, Average Loss: 86.1136\n",
      "Epoch 520, Average Loss: 84.8880\n",
      "Epoch 530, Average Loss: 83.0468\n",
      "Epoch 540, Average Loss: 81.2353\n",
      "Epoch 550, Average Loss: 81.4479\n",
      "Epoch 560, Average Loss: 82.6050\n",
      "Epoch 570, Average Loss: 83.0735\n",
      "Epoch 580, Average Loss: 80.7561\n",
      "Epoch 590, Average Loss: 80.4606\n",
      "Epoch 600, Average Loss: 81.5024\n",
      "Epoch 610, Average Loss: 80.7884\n",
      "Early stopping at epoch 612\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T07:04:17.833865Z",
     "start_time": "2024-11-26T07:04:16.915869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from function import calculate_metrics, metrics_to_dataframe\n",
    "\n",
    "# 加载最佳模型的状态字典\n",
    "model.load_state_dict(torch.load(\"lstm_best_model.pth\", weights_only=True))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 准备训练数据\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_predictions = []\n",
    "    y_train_true = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = reshape_for_lstm(X_batch)\n",
    "        outputs = model(X_batch)\n",
    "        train_predictions.append(outputs.cpu().numpy())\n",
    "        y_train_true.append(y_batch.cpu().numpy())\n",
    "\n",
    "    train_predictions = np.concatenate(train_predictions, axis=0)\n",
    "    y_train_true = np.concatenate(y_train_true, axis=0)\n",
    "\n",
    "    # 计算训练集的指标\n",
    "    train_metrics = calculate_metrics(y_train_true, train_predictions)\n",
    "    print(\"训练集指标:\", train_metrics)\n",
    "\n",
    "    # 准备测试数据\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_predictions = []\n",
    "    y_test_true = []\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = reshape_for_lstm(X_batch)\n",
    "        outputs = model(X_batch)\n",
    "        test_predictions.append(outputs.cpu().numpy())\n",
    "        y_test_true.append(y_batch.cpu().numpy())\n",
    "\n",
    "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "    y_test_true = np.concatenate(y_test_true, axis=0)\n",
    "\n",
    "    # 计算测试集的指标\n",
    "    test_metrics = calculate_metrics(y_test_true, test_predictions)\n",
    "    print(\"测试集指标:\", test_metrics)\n",
    "\n",
    "    # 将结果转换为DataFrame\n",
    "    lstm_metrics = metrics_to_dataframe(\n",
    "        y_train_true, train_predictions,\n",
    "        y_test_true, test_predictions, \"LSTM\").round(3)\n",
    "    lstm_metrics.to_csv('LSTM_metrics.csv', index=False)\n",
    "    print(lstm_metrics)\n"
   ],
   "id": "b8b38ebb7b444f9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集指标: (0.9745612740516663, 3.0919876, 2.9374679550528526, 6.3671594)\n",
      "测试集指标: (0.9454517960548401, 5.6696105, 6.96353018283844, 9.268903)\n",
      "  model  R2_train  MAE_train  MAPE_train  RMSE_train  R2_test  MAE_test  \\\n",
      "0  LSTM     0.975      3.092       2.937       6.367    0.945      5.67   \n",
      "\n",
      "   MAPE_test  RMSE_test  \n",
      "0      6.964      9.269  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:33:09.100110Z",
     "start_time": "2024-11-26T10:33:09.053373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存预测结果\n",
    "lstm_train = pd.DataFrame({'Actual': y_train_true, 'Predicted': train_predictions.squeeze()})\n",
    "lstm_test = pd.DataFrame({'Actual': y_test_true, 'Predicted': test_predictions.squeeze()})\n",
    "lstm_train.to_csv('lstm_train.csv', index=False)\n",
    "lstm_test.to_csv('lstm_test.csv', index=False)"
   ],
   "id": "89a0b250ede65b92",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
